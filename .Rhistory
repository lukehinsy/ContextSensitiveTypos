filter(Score==max(Score) | is.na(Score)) %>%
select(sugg)
}  else {
suggest<-data.frame(sugg=inp)
}
return(unlist(selected$sugg))
}
testdfsplitting$sugg2<-unlist(lapply(testdfsplitting$word,SplitWords))	#Crashes out b/c diff lengths.
#### Splitting concat words ####
#
# 1. Read in "misspellings", specifically those whose original was returned as suggested.
# 2. Among those, split at each letter and check those 2 words. IF both are words, and that's the only row that is 2 words, keep it.
# 3. If multiple rows tend to be marked as keepers, or non-keepers are being kept, then may need to incorporate a word "Score" based on ranking in the original database, as used in FixTypos(). Might need to anyway, because it's gonna be a little foolish to program under the assumption that it'll be fine...
#
#
inp<-"geico"
inp_nchar<-nchar(inp)
inp_breaklist<-data.frame("n"=1:inp_nchar,
"source.word"=rep(inp,inp_nchar))
inp_breaklist$word1<-substr(inp_breaklist$source.word,start=0,stop=inp_breaklist$n)
inp_breaklist$word2<-substr(inp_breaklist$source.word,start=inp_breaklist$n+1,inp_nchar)
selected<-inp_breaklist[hunspell::hunspell_check(toupper(inp_breaklist$word1))==TRUE & hunspell::hunspell_check(toupper(inp_breaklist$word2))==TRUE,]
SplitWords <-function(inp) {   ### will assume it gets just a list of words
inp_nchar<-nchar(inp)
inp_breaklist<-data.frame("n"=1:inp_nchar,
"source.word"=rep(inp,inp_nchar))
inp_breaklist$word1<-substr(inp_breaklist$source.word,start=0,stop=inp_breaklist$n)
inp_breaklist$word2<-substr(inp_breaklist$source.word,start=inp_breaklist$n+1,inp_nchar)
selected<-inp_breaklist[hunspell::hunspell_check(toupper(inp_breaklist$word1))==TRUE & hunspell::hunspell_check(toupper(inp_breaklist$word2))==TRUE,]
if (nrow(selected) >0) {
selected<- selected %>%
dplyr::left_join(rename(wordlist,count.1=n), by=c("word1"="word")) %>%
dplyr::left_join(rename(wordlist,count.2=n), by=c("word2"="word")) %>%
mutate(lncount.1=log(count.1),
lncount.2=log(count.2)) %>%
replace(is.na(.),0)  %>%
mutate(Score=rowMeans(select(.,lncount.1,lncount.2)), sugg=paste(word1,word2,sep=" ")) %>%
filter(Score==max(Score) | is.na(Score)) %>%
select(sugg)
}  else {
selected<-data.frame(sugg=inp)
}
return(unlist(selected$sugg))
}
testdfsplitting$sugg2<-unlist(lapply(testdfsplitting$word,SplitWords))	#Crashes out b/c diff lengths.
splitresults<-unlist(lapply(testdfsplitting$word,SplitWords))
View(splitresults)
View(testdfsplitting)
testdfsplitting[1251]
testdfsplitting[,1251]
testdfsplitting[1251,]
splitresults[1251]
testdfsplitting[1250,]
testdfsplitting[1,]
splitresults[1]
splitresults[43]
testdfsplitting[43]
testdfsplitting[43,]
testdfsplitting[430,]
testdfsplitting[430]
splitresults[430]
View(cbind(testdfsplitting,splitresults))
rbind(testdfsplitting,c("",""))
testdfsplitting<-rbind(testdfsplitting,c("",""))
View(cbind(testdfsplitting,splitresults))
selected$sugg[1]
SplitWords <-function(inp) {   ### will assume it gets just a list of words
inp_nchar<-nchar(inp)
inp_breaklist<-data.frame("n"=1:inp_nchar,
"source.word"=rep(inp,inp_nchar))
inp_breaklist$word1<-substr(inp_breaklist$source.word,start=0,stop=inp_breaklist$n)
inp_breaklist$word2<-substr(inp_breaklist$source.word,start=inp_breaklist$n+1,inp_nchar)
selected<-inp_breaklist[hunspell::hunspell_check(toupper(inp_breaklist$word1))==TRUE & hunspell::hunspell_check(toupper(inp_breaklist$word2))==TRUE,]
if (nrow(selected) >0) {
selected<- selected %>%
dplyr::left_join(rename(wordlist,count.1=n), by=c("word1"="word")) %>%
dplyr::left_join(rename(wordlist,count.2=n), by=c("word2"="word")) %>%
mutate(lncount.1=log(count.1),
lncount.2=log(count.2)) %>%
replace(is.na(.),0)  %>%
mutate(Score=rowMeans(select(.,lncount.1,lncount.2)), sugg=paste(word1,word2,sep=" ")) %>%
filter(Score==max(Score) | is.na(Score)) %>%
select(sugg)
}  else {
selected<-data.frame(sugg=inp)
}
return(unlist(selected$sugg[1]))
}
testdfsplitting$sugg2<-unlist(lapply(testdfsplitting$word,SplitWords))	#Crashes out b/c diff lengths.
#### Splitting concat words ####
#
# 1. Read in "misspellings", specifically those whose original was returned as suggested.
# 2. Among those, split at each letter and check those 2 words. IF both are words, and that's the only row that is 2 words, keep it.
# 3. If multiple rows tend to be marked as keepers, or non-keepers are being kept, then may need to incorporate a word "Score" based on ranking in the original database, as used in FixTypos(). Might need to anyway, because it's gonna be a little foolish to program under the assumption that it'll be fine...
#
#
inp<-"xxxx"
inp_nchar<-nchar(inp)
inp_breaklist<-data.frame("n"=1:inp_nchar,
"source.word"=rep(inp,inp_nchar))
inp_breaklist$word1<-substr(inp_breaklist$source.word,start=0,stop=inp_breaklist$n)
inp_breaklist$word2<-substr(inp_breaklist$source.word,start=inp_breaklist$n+1,inp_nchar)
selected<-inp_breaklist[hunspell::hunspell_check(toupper(inp_breaklist$word1))==TRUE & hunspell::hunspell_check(toupper(inp_breaklist$word2))==TRUE,]
selected<- selected %>%
dplyr::left_join(rename(wordlist,count.1=n), by=c("word1"="word")) %>%
dplyr::left_join(rename(wordlist,count.2=n), by=c("word2"="word")) %>%
mutate(lncount.1=log(count.1),
lncount.2=log(count.2)) %>%
replace(is.na(.),0)  %>%
mutate(Score=rowMeans(select(.,lncount.1,lncount.2)), sugg=paste(word1,word2,sep=" ")) %>%
filter(Score==max(Score) | is.na(Score)) %>%
select(sugg)
selected$sugg[1]
unlist(selected$sugg[1])
SplitWords <-function(inp) {   ### will assume it gets just a list of words
inp_nchar<-nchar(inp)
inp_breaklist<-data.frame("n"=1:inp_nchar,
"source.word"=rep(inp,inp_nchar))
inp_breaklist$word1<-substr(inp_breaklist$source.word,start=0,stop=inp_breaklist$n)
inp_breaklist$word2<-substr(inp_breaklist$source.word,start=inp_breaklist$n+1,inp_nchar)
selected<-inp_breaklist[hunspell::hunspell_check(toupper(inp_breaklist$word1))==TRUE & hunspell::hunspell_check(toupper(inp_breaklist$word2))==TRUE,]
if (nrow(selected) >0) {
selected<- selected %>%
dplyr::left_join(rename(wordlist,count.1=n), by=c("word1"="word")) %>%
dplyr::left_join(rename(wordlist,count.2=n), by=c("word2"="word")) %>%
mutate(lncount.1=log(count.1),
lncount.2=log(count.2)) %>%
replace(is.na(.),0)  %>%
mutate(Score=rowMeans(select(.,lncount.1,lncount.2)), sugg=paste(word1,word2,sep=" ")) %>%
filter(Score==max(Score) | is.na(Score)) %>%
select(sugg)
}  else {
selected<-data.frame(sugg=inp)
}
return(selected$sugg[1])
}
testdfsplitting$sugg2<-unlist(lapply(testdfsplitting$word,SplitWords))	#Crashes out b/c diff lengths.
#### Splitting concat words ####
#
# 1. Read in "misspellings", specifically those whose original was returned as suggested.
# 2. Among those, split at each letter and check those 2 words. IF both are words, and that's the only row that is 2 words, keep it.
# 3. If multiple rows tend to be marked as keepers, or non-keepers are being kept, then may need to incorporate a word "Score" based on ranking in the original database, as used in FixTypos(). Might need to anyway, because it's gonna be a little foolish to program under the assumption that it'll be fine...
#
#
inp<-NULL
testdfsplitting$sugg2<-unlist(lapply(testdfsplitting$word,SplitWords))	#Crashes out b/c diff lengths.
splitresults<-unlist(lapply(testdfsplitting$word,SplitWords))
inp_nchar<-NULL
inp_breaklist<-NULL
testdfsplitting$sugg2<-unlist(lapply(testdfsplitting$word,SplitWords))	#Crashes out b/c diff lengths.
inp<-NULL
#### Splitting concat words ####
#
# 1. Read in "misspellings", specifically those whose original was returned as suggested.
# 2. Among those, split at each letter and check those 2 words. IF both are words, and that's the only row that is 2 words, keep it.
# 3. If multiple rows tend to be marked as keepers, or non-keepers are being kept, then may need to incorporate a word "Score" based on ranking in the original database, as used in FixTypos(). Might need to anyway, because it's gonna be a little foolish to program under the assumption that it'll be fine...
#
#
inp<-NA
testdfsplitting$sugg2<-unlist(lapply(testdfsplitting$word,SplitWords))	#Crashes out b/c diff lengths.
#### Splitting concat words ####
#
# 1. Read in "misspellings", specifically those whose original was returned as suggested.
# 2. Among those, split at each letter and check those 2 words. IF both are words, and that's the only row that is 2 words, keep it.
# 3. If multiple rows tend to be marked as keepers, or non-keepers are being kept, then may need to incorporate a word "Score" based on ranking in the original database, as used in FixTypos(). Might need to anyway, because it's gonna be a little foolish to program under the assumption that it'll be fine...
#
#
inp<-"testing"
inp_nchar<-nchar(inp)
inp_breaklist<-data.frame("n"=1:inp_nchar,
"source.word"=rep(inp,inp_nchar))
inp_breaklist$word1<-substr(inp_breaklist$source.word,start=0,stop=inp_breaklist$n)
inp_breaklist$word2<-substr(inp_breaklist$source.word,start=inp_breaklist$n+1,inp_nchar)
SplitWords <-function(inp) {   ### will assume it gets just a list of words
inp_nchar<-nchar(inp)
inp_breaklist<-data.frame("n"=1:inp_nchar,
"source.word"=rep(inp,inp_nchar))
inp_breaklist$word1<-substr(inp_breaklist$source.word,start=0,stop=inp_breaklist$n)
inp_breaklist$word2<-substr(inp_breaklist$source.word,start=inp_breaklist$n+1,inp_nchar)
selected<-inp_breaklist[hunspell::hunspell_check(toupper(inp_breaklist$word1))==TRUE & hunspell::hunspell_check(toupper(inp_breaklist$word2))==TRUE,]
if (nrow(selected) >0) {
selected<- selected %>%
dplyr::left_join(rename(wordlist,count.1=n), by=c("word1"="word")) %>%
dplyr::left_join(rename(wordlist,count.2=n), by=c("word2"="word")) %>%
mutate(lncount.1=log(count.1),
lncount.2=log(count.2)) %>%
replace(is.na(.),0)  %>%
mutate(Score=rowMeans(select(.,lncount.1,lncount.2)), sugg=paste(word1,word2,sep=" ")) %>%
filter(Score==max(Score) | is.na(Score)) %>%
select(sugg)
}  else {
selected<-data.frame(sugg=inp)
}
return(selected$sugg[1])
}
FixTypos<-function(df, text) {
# Required packages #
require(dplyr)
require(tm)
require(tidytext)
require(hunspell)
wordlist<-df %>% select({{text}}) %>%
dplyr::mutate(text=tm::removePunctuation({{text}},preserve_intra_word_contractions=TRUE)) %>%
tidytext::unnest_tokens(word, text, token="words",to_lower=TRUE, strip_punct=FALSE, strip_numeric=TRUE) %>%
dplyr::count(word, sort=TRUE) %>%
dplyr::select(word)
wordlist$correct<-hunspell::hunspell_check(toupper(wordlist$word))
correctwords<-wordlist %>% filter(correct==TRUE)
misspellings<-wordlist %>% filter(correct==FALSE)
correct <-function(word) {c(correctwords[adist(word, correctwords$word) <= min(adist(word, correctwords$word), 2)], word)[1]}
misspellings$sugg<-unlist(lapply(misspellings$word, correct))    ## THIS IS INCREDIBLY SLOW!
misspellings <- misspellings %>% select(word, sugg)
return(misspellings)
## Currently returning just the typos and top suggestion. Can use that df as a dictionary to grepl fix.
# Might, however, want to change this behavior.
}
testsplit<-FixTypos(testdata,Q1A)
testsplit<-subset(testsplit,word==sugg)
testsplit$sugg2<-(unlist(lapply(testsplit$word,SplitWords)))
FixTypos<-function(df, text) {
# Required packages #
require(dplyr)
require(tm)
require(tidytext)
require(hunspell)
wordlist<-df %>% select({{text}}) %>%
dplyr::mutate(text=tm::removePunctuation({{text}},preserve_intra_word_contractions=TRUE)) %>%
tidytext::unnest_tokens(word, text, token="words",to_lower=TRUE, strip_punct=FALSE, strip_numeric=TRUE) %>%
dplyr::count(word, sort=TRUE) %>%
dplyr::select(word,n)
wordlist$correct<-hunspell::hunspell_check(toupper(wordlist$word))
correctwords<-wordlist %>% filter(correct==TRUE)
misspellings<-wordlist %>% filter(correct==FALSE)
correct <-function(word) {c(correctwords[adist(word, correctwords$word) <= min(adist(word, correctwords$word), 2)], word)[1]}
misspellings$sugg<-unlist(lapply(misspellings$word, correct))    ## THIS IS INCREDIBLY SLOW!
misspellings <- misspellings %>% select(word, sugg)
return(misspellings)
## Currently returning just the typos and top suggestion. Can use that df as a dictionary to grepl fix.
# Might, however, want to change this behavior.
}
test<-lapply(c("testthis","anotherone","a"),SplitWords)
testsplit<-FixTypos(testdata,Q1A)
RecTable<-misspellings %>% left_join(possconcat)
misspellings<-testsplit
possconcat<-subset(misspellings, word==sugg) %>% select(word)
possconcat$split<-(unlist(lapply(possconcat$word,SplitWords)))
RecTable<-misspellings %>% left_join(possconcat)
View(RecTable)
RecTable$sugg[RecTable$word==RecTable$sugg]<-RecTable$split
RecTable$sugg[RecTable$word==RecTable$sugg]<-RecTable$split[RecTable$word==RecTable$sugg]
RecTable$sugg[RecTable$word==RecTable$sugg]<-RecTable$split[RecTable$word==RecTable$sugg]
RecTable$sugg[RecTable$word==RecTable$sugg & !is.na(split)]<-RecTable$split[RecTable$word==RecTable$sugg & !is.na(split)]
View(RecTable)
View(misspellings)
RecTable<-misspellings %>% left_join(possconcat)
View(RecTable)
RecTable$sugg[RecTable$word==RecTable$sugg]<-RecTable$split[RecTable$word==RecTable$sugg]
RecTable$sugg[RecTable$sugg=="i"]<-RecTable$word[RecTable$sugg=="i"]
FixTypos<-function(df, text) {
# Required packages #
require(dplyr)
require(tm)
require(tidytext)
require(hunspell)
wordlist<-df %>% select({{text}}) %>%
dplyr::mutate(text=tm::removePunctuation({{text}},preserve_intra_word_contractions=TRUE)) %>%
tidytext::unnest_tokens(word, text, token="words",to_lower=TRUE, strip_punct=FALSE, strip_numeric=TRUE) %>%
dplyr::count(word, sort=TRUE) %>%
dplyr::select(word,n)
wordlist$correct<-hunspell::hunspell_check(toupper(wordlist$word))
correctwords<-wordlist %>% filter(correct==TRUE)
misspellings<-wordlist %>% filter(correct==FALSE)
correct <-function(word) {c(correctwords[adist(word, correctwords$word) <= min(adist(word, correctwords$word), 2)], word)[1]}
misspellings$sugg<-unlist(lapply(misspellings$word, correct))    ## THIS IS INCREDIBLY SLOW!
misspellings <- misspellings %>% select(word, sugg)
SplitWords <-function(inp) {   ### will assume it gets just a list of words
inp_nchar<-nchar(inp)
inp_breaklist<-data.frame("n"=1:inp_nchar,
"source.word"=rep(inp,inp_nchar))
inp_breaklist$word1<-substr(inp_breaklist$source.word,start=0,stop=inp_breaklist$n)
inp_breaklist$word2<-substr(inp_breaklist$source.word,start=inp_breaklist$n+1,inp_nchar)
selected<-inp_breaklist[hunspell::hunspell_check(toupper(inp_breaklist$word1))==TRUE & hunspell::hunspell_check(toupper(inp_breaklist$word2))==TRUE,]
if (nrow(selected) >0) {
selected<- selected %>%
dplyr::left_join(rename(wordlist,count.1=n), by=c("word1"="word")) %>%
dplyr::left_join(rename(wordlist,count.2=n), by=c("word2"="word")) %>%
mutate(lncount.1=log(count.1),
lncount.2=log(count.2)) %>%
replace(is.na(.),0)  %>%
mutate(Score=rowMeans(select(.,lncount.1,lncount.2)), sugg=paste(word1,word2,sep=" ")) %>%
filter(Score==max(Score) | is.na(Score)) %>%
select(sugg)
}  else {
selected<-data.frame(sugg=inp)
}
return(selected$sugg[1])
}
possconcat<-subset(misspellings, word==sugg) %>% select(word)
possconcat$split<-(unlist(lapply(possconcat$word,SplitWords)))
RecTable<-misspellings %>% left_join(possconcat)
RecTable$sugg[RecTable$word==RecTable$sugg]<-RecTable$split[RecTable$word==RecTable$sugg]
RecTable$sugg[RecTable$sugg=="i"]<-RecTable$word[RecTable$sugg=="i"]
# if (fix=TRUE) {
#		return(GREPL ORIGINAL COLUMN)
#  } else {
#		return(TABLE OF SUGGESTED REPLACEMENTS)
#  }
return(misspellings)
# return(misspellings)
## Currently returning just the typos and top suggestion. Can use that df as a dictionary to grepl fix.
# Might, however, want to change this behavior.
}
test<-FixTypos(testdata,Q1A)
View(test)
FixTypos<-function(df, text) {
# Required packages #
require(dplyr)
require(tm)
require(tidytext)
require(hunspell)
wordlist<-df %>% select({{text}}) %>%
dplyr::mutate(text=tm::removePunctuation({{text}},preserve_intra_word_contractions=TRUE)) %>%
tidytext::unnest_tokens(word, text, token="words",to_lower=TRUE, strip_punct=FALSE, strip_numeric=TRUE) %>%
dplyr::count(word, sort=TRUE) %>%
dplyr::select(word,n)
wordlist$correct<-hunspell::hunspell_check(toupper(wordlist$word))
correctwords<-wordlist %>% filter(correct==TRUE)
misspellings<-wordlist %>% filter(correct==FALSE)
correct <-function(word) {c(correctwords[adist(word, correctwords$word) <= min(adist(word, correctwords$word), 2)], word)[1]}
misspellings$sugg<-unlist(lapply(misspellings$word, correct))    ## THIS IS INCREDIBLY SLOW!
misspellings <- misspellings %>% select(word, sugg)
SplitWords <-function(inp) {   ### will assume it gets just a list of words
inp_nchar<-nchar(inp)
inp_breaklist<-data.frame("n"=1:inp_nchar,
"source.word"=rep(inp,inp_nchar))
inp_breaklist$word1<-substr(inp_breaklist$source.word,start=0,stop=inp_breaklist$n)
inp_breaklist$word2<-substr(inp_breaklist$source.word,start=inp_breaklist$n+1,inp_nchar)
selected<-inp_breaklist[hunspell::hunspell_check(toupper(inp_breaklist$word1))==TRUE & hunspell::hunspell_check(toupper(inp_breaklist$word2))==TRUE,]
if (nrow(selected) >0) {
selected<- selected %>%
dplyr::left_join(rename(wordlist,count.1=n), by=c("word1"="word")) %>%
dplyr::left_join(rename(wordlist,count.2=n), by=c("word2"="word")) %>%
mutate(lncount.1=log(count.1),
lncount.2=log(count.2)) %>%
replace(is.na(.),0)  %>%
mutate(Score=rowMeans(select(.,lncount.1,lncount.2)), sugg=paste(word1,word2,sep=" ")) %>%
filter(Score==max(Score) | is.na(Score)) %>%
select(sugg)
}  else {
selected<-data.frame(sugg=inp)
}
return(selected$sugg[1])
}
possconcat<-subset(misspellings, word==sugg) %>% select(word)
possconcat$split<-(unlist(lapply(possconcat$word,SplitWords)))
RecTable<-misspellings %>% left_join(possconcat)
RecTable$sugg[RecTable$word==RecTable$sugg]<-RecTable$split[RecTable$word==RecTable$sugg]
RecTable$sugg[RecTable$sugg=="i"]<-RecTable$word[RecTable$sugg=="i"]
# if (fix=TRUE) {
#		return(GREPL ORIGINAL COLUMN)
#  } else {
#		return(TABLE OF SUGGESTED REPLACEMENTS)
#  }
return(RecTable)
# return(misspellings)
## Currently returning just the typos and top suggestion. Can use that df as a dictionary to grepl fix.
# Might, however, want to change this behavior.
}
tic<-proc.time()
toc<-proc.time()-tic
tic
test<-FixTypos(testdata,Q1A)
toc
test<-test %>% select(-split)
data("data_corpus_inaugural", package = "quanteda")
force(data_corpus_inaugural)
inaug_dfm <- quanteda::dfm(data_corpus_inaugural, verbose = FALSE)
inaug_dfm
View(inaug_dfm)
library(topicmodels)
data("AssociatedPress")
AssociatedPress
ap_lda <- LDA(AssociatedPress, k = 2, control = list(seed = 1234))
ap_lda
library(tidytext)
ap_topics <- tidy(ap_lda, matrix = "beta")
ap_topics
library(ggplot2)
library(dplyr)
ap_top_terms <- ap_topics %>%
group_by(topic) %>%
top_n(10, beta) %>%
ungroup() %>%
arrange(topic, -beta)
ap_top_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
scale_y_reordered()
library(tidyr)
beta_spread <- ap_topics %>%
mutate(topic = paste0("topic", topic)) %>%
spread(topic, beta) %>%
filter(topic1 > .001 | topic2 > .001) %>%
mutate(log_ratio = log2(topic2 / topic1))
beta_spread
ap_documents <- tidy(ap_lda, matrix = "gamma")
ap_documents
titles <- c("Twenty Thousand Leagues under the Sea",
"The War of the Worlds",
"Pride and Prejudice",
"Great Expectations")
library(gutenbergr)
books <- gutenberg_works(title %in% titles) %>%
gutenberg_download(meta_fields = "title")
books <- gutenberg_works(title %in% titles) %>%
gutenberg_download(meta_fields = "title")
library(stringr)
# divide into documents, each representing one chapter
by_chapter <- books %>%
group_by(title) %>%
mutate(chapter = cumsum(str_detect(
text, regex("^chapter ", ignore_case = TRUE)
))) %>%
ungroup() %>%
filter(chapter > 0) %>%
unite(document, title, chapter)
# split into words
by_chapter_word <- by_chapter %>%
unnest_tokens(word, text)
# find document-word counts
word_counts <- by_chapter_word %>%
anti_join(stop_words) %>%
count(document, word, sort = TRUE) %>%
ungroup()
word_counts
chapters_dtm <- word_counts %>%
cast_dtm(document, word, n)
chapters_dtm
chapter_topics <- tidy(chapters_lda, matrix = "beta")
chapter_topics
chapters_lda <- LDA(chapters_dtm, k = 4, control = list(seed = 1234))
chapters_lda
chapter_topics <- tidy(chapters_lda, matrix = "beta")
chapter_topics
top_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
scale_y_reordered()
top_terms <- chapter_topics %>%
group_by(topic) %>%
top_n(5, beta) %>%
ungroup() %>%
arrange(topic, -beta)
top_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
scale_y_reordered()
chapters_gamma <- tidy(chapters_lda, matrix = "gamma")
chapters_gamma
chapters_gamma <- chapters_gamma %>%
separate(document, c("title", "chapter"), sep = "_", convert = TRUE)
chapters_gamma
# reorder titles in order of topic 1, topic 2, etc before plotting
chapters_gamma %>%
mutate(title = reorder(title, gamma * topic)) %>%
ggplot(aes(factor(topic), gamma)) +
geom_boxplot() +
facet_wrap(~ title) +
labs(x = "topic", y = expression(gamma))
chapter_classifications <- chapters_gamma %>%
group_by(title, chapter) %>%
slice_max(gamma) %>%
ungroup()
chapter_classifications
book_topics <- chapter_classifications %>%
count(title, topic) %>%
group_by(title) %>%
top_n(1, n) %>%
ungroup() %>%
transmute(consensus = title, topic)
chapter_classifications %>%
inner_join(book_topics, by = "topic") %>%
filter(title != consensus)
assignments <- augment(chapters_lda, data = chapters_dtm)
assignments
assignments <- assignments %>%
separate(document, c("title", "chapter"),
sep = "_", convert = TRUE) %>%
inner_join(book_topics, by = c(".topic" = "topic"))
assignments
library(scales)
assignments %>%
count(title, consensus, wt = count) %>%
mutate(across(c(title, consensus), ~str_wrap(., 20))) %>%
group_by(title) %>%
mutate(percent = n / sum(n)) %>%
ggplot(aes(consensus, title, fill = percent)) +
geom_tile() +
scale_fill_gradient2(high = "darkred", label = percent_format()) +
theme_minimal() +
theme(axis.text.x = element_text(angle = 90, hjust = 1),
panel.grid = element_blank()) +
labs(x = "Book words were assigned to",
y = "Book words came from",
fill = "% of assignments")
View(chapters_dtm)
